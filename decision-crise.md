# Prise de décision en situation de crise

> Cours de M. Didier Danet, Saint-Cyr Coëtquidan

- [Situation de crise](#situation-de-crise)
- [Les erreurs de décision](#les-erreurs-de-décision)
  - [Erreur cognitive](#erreur-cognitive)
  - [Erreur collective](#erreur-collective)
  - [Erreur téléologique](#erreur-téléologique)
- [Eviter les erreurs de décision](#eviter-les-erreurs-de-décision)
  - [Améliorer les interactions](#améliorer-les-interactions)
    - [Dire](#dire)
    - [Apprendre](#apprendre)
    - [Comprendre](#comprendre)

## Situation de crise

Le modèle CYNEFIN de Dave Snowden.

![CYNEFIN framework by Dave Snowden](https://wikiagile.cesi.fr/images/thumb/c/ce/Cynefin-by-Vige_en.png/1000px-Cynefin-by-Vige_en.png)

![Le modèle CYNEFIN de Dave Snowden](https://64.media.tumblr.com/1042f90f9aa90d1563e72ff9399011dd/tumblr_p054oauVDH1qzx36ho1_1280.jpg)

## Les erreurs de décision

En étudiant les catastrophes, on se rend compte que :
> *les individus prennent collectivement des décisions singulières et agissent avec constance dans le sens totalement contraire au but recherché*, Christian Morel dans *Les décisions absurdes*

Mais pourquoi ?

### Erreur cognitive

Les acteurs peuvent commettre des erreurs quand leur **perception** ou leur **jugement** est biaisé (voir [biais cognitifs](https://fr.wikipedia.org/wiki/Biais_cognitif)).

On peut distinguer 4 types d'erreurs :
- **Inattention** : manque d'intérêt pour la tâche en cours (ex: l’hôtesse annonce que la porte de l’avion est fermée alors qu’elle est ouverte)
- **Lacune** : manque de savoir ou de savoir-faire dans l’exécution d’une tâche (le pilote ne sait pas faire décoller un avion par temps de pluie)
- **Transgression** : violation délibérée d'une règle de comportement (ex: le pilote décolle alors qu’il n’a pas reçu l’autorisation)
- **Représentation** : on applique un raisonnement à une configuration connue, sans réaliser que cette configuration peut changer

L'erreur de représentation est la plus commune dans les accidents aériens. Par exemple : à cause du brouillard, le pilote doit décoller sur une autre piste en parallèle, il commence à décoller mais se rend compte que la piste est plus courte, elle n'était pas plus courte, mais décalée par rapport à l'autre piste.

En situation de crise, l’urgence et la pression favorisent les erreurs de représentation, car avec moins de temps pour analyser la situation, on se repose sur le fonctionnement automatique du cerveau, en faisant des raccourcis dans notre raisonnement.

### Erreur collective

Le mauvais fonctionnement des équipes peut pousser à prendre de mauvaises décisions.

On peut distinguer 3 types de biais dans les décisions collectives.

Le **mauvais partage des rôles entre expert et manager**. En temps normal, les experts analysent et conseillent, les managers décident et assument. Des dérives peuvent apparaitre lorsque :
- les managers décident sans tenir compte des experts (ex: trump et Fauci)
- les experts imposent la décision (boîte noire de l'expertise)

Les **interactions inefficaces**. Les processus de coordination doivent permettre d’échanger correctement les informations nécessaires à la prise de décision.
Les défaillances qui peuvent porter sur les processus de coordination :
- pas de check-list
- différences d’expérience professionnelle
- malentendu

L'**étanchéité**. L'équipe de décision pourrait bénéficier d'un apport/avis/point de vue extérieur lui permettant d'éclairer sa décision, mais ne le fait pas, ou ne le prend pas en compte, par inconsidération ou par rigidité de l'organisation. Un exemple exagéré serait un passager qui signale au personnel navigant une défaillance moteur, mais l'info n'est pas remontée car c'est juste un passager, ou parce qu'il n'est pas prévu qu'un passager puisse remonter une info au pilote.

Raisons de l'étanchéité :
- équipe narcissique et fermée sur l'extérieur
- impossible traduction : le tiers ne sait pas formuler ses observations dans des termes compréhensibles par l'équipe (ex: barrière de la langue, témoin d'un accident qui décrit des mal des symptômes)
- impossible immixtion : le tiers n’a pas de légitimité pour intervenir dans le processus de décision (ex: le passager de l'avion)

### Erreur téléologique

Les décideurs peuvent perdre de vue le sens de l’action.

Le décideur commence et poursuit son action alors qu’elle va directement à l’encontre de l’objectif poursuivi et que l’action perd tout son sens. La démonstration de savoir-faire devient la finalité et fait perdre de vue l’objectif initial. Le **comment** l’emporte sur le **pourquoi**. Un exemple est le solutionnisme technologique, on se concentre sur l'outil et on se détourne du sens de l'objectif (ex: appli tousanticovid).

Voir aussi [le problème XY](https://xyproblem.info/) et l'[effet Einstellung](https://en.wikipedia.org/wiki/Einstellung_effect).

## Eviter les erreurs de décision

Deux types d'effet peuvent miner les décisions collectives.

**Les effets de groupe** :
- primauté de la cohésion (par le taisement des opinions divergentes)
- soumission à l'autorité ([expérience de Milgram](https://fr.wikipedia.org/wiki/Exp%C3%A9rience_de_Milgram))
- communication silencieus excessive ([effet de Halo](https://fr.wikipedia.org/wiki/Effet_de_halo) ou le positionnement en fonction des opinions prêtées à autrui)
- polarisation sur les opinions extrêmes

Pour contrer ces biais, on peut :
- faire l'avocat du diable pour introduire les opinions minoritaires et susciter le débat
- stabiliser les équipes pour obtenir une meilleur connaissance réciproque des acteurs
- diversifier les équipes pour limiter une polarisation des idées
- restreindre la taille du groupe pour limiter l'impact des opinions extrêmes

**Les interstices** sont les lieux où une organisation entre en contact avec d’autres organisations (équipe suivante, autre service, fournisseur, client, partenaire).

Les interstices jouent un rôle majeur dans les dysfonctionnements et la production d’erreurs absurdes à cause de :
- **opportunisme structurel** : chaque fraction d'une organisation a des intérêts partiellement convergents et partiellement divergents
- **erreurs de représentation** : chaque métier/groupe a sa culture, ce qui va mener à des divergences (vocabulaire, point de vue)

Pour contrer ce bazar :
- ne pas fractionner les structures à l'excès : `plus de groupes -> plus d'interstice`
- favoriser les échanges, créer les conditions d'un apprentissage commun pour créer une culture commune

### Améliorer les interactions

#### Dire

**Renforcement** ou **explication** des interactions pour améliorer la sûreté de la transmission :
- l'utilisation de [checklist](https://en.wikipedia.org/wiki/Checklist) permet les erreurs de la coordination silencieuse (pratique courante et acceptée dans l'aviation et l'aérospatiale. Il a fallut du temps pour que ça débarque dans les blocs chirurgicaux, mais il arrive encore que des chirurgiens opèrent du mauvais côté, pourtant les enjeux sont les mêmes, des $ et des vies)
- l'utilisation de l'[alphabet phonétique de l'OTAN](https://fr.wikipedia.org/wiki/Alphabet_phon%C3%A9tique_de_l%27OTAN) permet de résorber l’ambiguïté du langage
- la mise en place de [protocole](https://fr.wikipedia.org/wiki/Protocole) permet d'imposer des règles d'action communes

#### Apprendre

Décrire et analyser les événements vécus par l’organisation pour en tirer des **enseignements** et les **diffuser**.

Pour cela les [**RETEX**](https://fr.wikipedia.org/wiki/Retour_d%27exp%C3%A9rience) sont un bon outil, faire attention à :
- **selectionner** les cas traités pour ne pas faire de RETEX sur tout ce qu'il se passe
- choisir une **forme** parlante (storytelling)
- ne pas faire de RETEX que sur des événements techniques, mais aussi **humains** et **organisationnelles**

#### Comprendre

Il est important de comprendre que les systèmes de décision sont des systèmes socio-techniques, qui doivent aussi prendre en compte le facteur **humain** et organisationnel.
La seule solution technique ne suffit pas. Par exemple la règle selon laquelle un mot de passe doit contenir des majuscules, des chiffres et des caractères spéciaux les rend **plus difficile à retenir**, et ils finissent écris sur un post-it, ce qui est contre-productif.

D'ailleurs, même au niveau technique, cette règle est éclatée au sol :
1. un mot de passe compliqué de 10 caractère restera moins sûr qu'un mot de passe simple de 14 caractères
2. les outils d'attaque par dictionnaire savent partir de `martine du 56` pour générer plein de modifications comme `M4rtine du 77`, il y a donc là une fausse impression de sécurité
3. le [NIST](https://www.sans.org/blog/nist-has-spoken-death-to-complexity-long-live-the-passphrase/) recommande des passphrase plutôt que des password, donc c'est bien

[![XKCD](https://imgs.xkcd.com/comics/password_strength.png)](https://www.nist.gov/blogs/taking-measure/easy-ways-build-better-p5w0rd)
